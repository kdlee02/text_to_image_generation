{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3TdCSmD4tKT",
        "outputId": "f9de21f2-0a47-4389-ac9e-9cc165d74ab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting aesthetic-predictor-v2-5\n",
            "  Downloading aesthetic_predictor_v2_5-2024.12.18.1-py2.py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate>=0.30 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (1.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.17 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.40 in /usr/local/lib/python3.12/dist-packages (from aesthetic-predictor-v2-5) (4.56.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (0.35.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=0.30->aesthetic-predictor-v2-5) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.2->aesthetic-predictor-v2-5) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.17->aesthetic-predictor-v2-5) (11.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->aesthetic-predictor-v2-5) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->aesthetic-predictor-v2-5) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->aesthetic-predictor-v2-5) (0.22.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.40->aesthetic-predictor-v2-5) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=0.30->aesthetic-predictor-v2-5) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.2->aesthetic-predictor-v2-5) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.2->aesthetic-predictor-v2-5) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40->aesthetic-predictor-v2-5) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40->aesthetic-predictor-v2-5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40->aesthetic-predictor-v2-5) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.40->aesthetic-predictor-v2-5) (2025.8.3)\n",
            "Downloading aesthetic_predictor_v2_5-2024.12.18.1-py2.py3-none-any.whl (28 kB)\n",
            "Installing collected packages: aesthetic-predictor-v2-5\n",
            "Successfully installed aesthetic-predictor-v2-5-2024.12.18.1\n"
          ]
        }
      ],
      "source": [
        "!pip install fal-client requests python-dotenv pillow torch\n",
        "!pip install aesthetic-predictor-v2-5\n",
        "!wget https://openaipublic.blob.core.windows.net/clip/bpe_simple_vocab_16e6.txt.gz -P /usr/local/lib/python3.12/dist-packages/hpsv2/src/open_clip/\n",
        "!pip install hpsv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RatMnE6Z4vKU",
        "outputId": "6f11e3ec-af18-4a3b-d99f-367815d4a2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ All imports loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import fal_client\n",
        "import os\n",
        "import requests\n",
        "import time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Optional, Dict, Tuple\n",
        "from dotenv import load_dotenv\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import torch\n",
        "from IPython.display import display, HTML\n",
        "from aesthetic_predictor_v2_5 import convert_v2_5_from_siglip\n",
        "import hpsv2\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"✅ All imports loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEyWJKw_4yuy",
        "outputId": "bc13f9be-fba9-44b9-b508-d8dbb8d1e7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ ImageGenerator class defined!\n"
          ]
        }
      ],
      "source": [
        "class ImageGenerator:\n",
        "    \"\"\"Simple image generator with aesthetic evaluation.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the generator with FAL AI and aesthetic model.\"\"\"\n",
        "        # Setup FAL AI\n",
        "        if api_key:\n",
        "            os.environ['FAL_KEY'] = api_key\n",
        "        elif not os.getenv('FAL_KEY'):\n",
        "            raise ValueError(\"API key required. Set FAL_KEY environment variable or provide api_key parameter.\")\n",
        "\n",
        "        # Initialize aesthetic model\n",
        "        print(\"Loading aesthetic evaluation model...\")\n",
        "        self.model, self.preprocessor = convert_v2_5_from_siglip(\n",
        "            low_cpu_mem_usage=True,\n",
        "            trust_remote_code=True,\n",
        "        )\n",
        "        self.model = self.model.to(torch.bfloat16).cuda()\n",
        "        print(\"✅ Aesthetic model loaded successfully!\")\n",
        "\n",
        "    def generate_image(self, prompt: str, model: str = \"fal-ai/imagen4/preview\") -> Tuple[str, Dict]:\n",
        "        \"\"\"Generate image using FAL AI.\"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        try:\n",
        "            response = fal_client.run(\n",
        "                model,\n",
        "                arguments={\n",
        "                    \"prompt\": prompt,\n",
        "                    \"image_size\": \"square_hd\",\n",
        "                    \"num_inference_steps\": 50,\n",
        "                    \"guidance_scale\": 7.5\n",
        "                }\n",
        "            )\n",
        "\n",
        "            end_time = time.time()\n",
        "\n",
        "            if response and \"images\" in response and len(response[\"images\"]) > 0:\n",
        "                image_url = response[\"images\"][0][\"url\"]\n",
        "                metadata = {\n",
        "                    \"model\": model,\n",
        "                    \"prompt\": prompt,\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"generation_time\": end_time - start_time,\n",
        "                    \"response\": response\n",
        "                }\n",
        "                return image_url, metadata\n",
        "            else:\n",
        "                raise Exception(\"No image generated in response\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Failed to generate image: {str(e)}\")\n",
        "\n",
        "    def download_image(self, url: str) -> Image.Image:\n",
        "        \"\"\"Download image from URL and return PIL Image.\"\"\"\n",
        "        try:\n",
        "            response = requests.get(url, timeout=30, stream=True)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_file:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    tmp_file.write(chunk)\n",
        "                tmp_path = tmp_file.name\n",
        "\n",
        "            image = Image.open(tmp_path).convert(\"RGB\")\n",
        "            os.unlink(tmp_path)\n",
        "\n",
        "            return image\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error downloading image: {str(e)}\")\n",
        "\n",
        "    def calculate_aesthetic_score(self, image: Image.Image) -> float:\n",
        "        \"\"\"Calculate aesthetic score using the v2.5 model.\"\"\"\n",
        "        try:\n",
        "            # preprocess image\n",
        "            pixel_values = (\n",
        "                self.preprocessor(images=image, return_tensors=\"pt\")\n",
        "                .pixel_values.to(torch.bfloat16).cuda()\n",
        "            )\n",
        "\n",
        "            # predict aesthetic score\n",
        "            with torch.inference_mode():\n",
        "                score = self.model(pixel_values).logits.squeeze().float().cpu().numpy()\n",
        "\n",
        "            return float(score)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating aesthetic score: {str(e)}\")\n",
        "            return 0.0\n",
        "\n",
        "    def calculate_hpvs2(self, image: Image.Image, prompt: str) -> float:\n",
        "        \"\"\"Calculate hpsv2 score\"\"\"\n",
        "        try:\n",
        "\n",
        "          hpscore = hpsv2.score(image,prompt,hps_version='v2.1')\n",
        "          return float(hpscore[0])\n",
        "\n",
        "        except Exception as e:\n",
        "          print(f'error: {e}')\n",
        "\n",
        "    def generate_and_evaluate(self, prompt: str) -> Dict:\n",
        "        \"\"\"Generate image and calculate aesthetic score.\"\"\"\n",
        "        print(f\"\\n🎯 Generating image for prompt: '{prompt}'\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Generate image\n",
        "            print(\"\\n1️⃣ Generating image with FAL AI Imagen4...\")\n",
        "            image_url, metadata = self.generate_image(prompt)\n",
        "            print(f\"✅ Image generated in {metadata['generation_time']:.2f}s\")\n",
        "\n",
        "            # Step 2: Download image for aesthetic evaluation\n",
        "            print(\"\\n2️⃣ Downloading image for evaluation...\")\n",
        "            image = self.download_image(image_url)\n",
        "            print(\"✅ Image downloaded successfully\")\n",
        "\n",
        "            # Step 3: Calculate aesthetic score\n",
        "            print(\"\\n3️⃣ Calculating aesthetic score...\")\n",
        "            aesthetic_score = self.calculate_aesthetic_score(image)\n",
        "            print(\"✅ Aesthetic evaluation complete\")\n",
        "\n",
        "            # log the\n",
        "            print(\"\\n3️⃣ Calculating HPSv2 score...\")\n",
        "            hpscore = self.calculate_hpvs2(image,prompt)\n",
        "            print(\"✅ HPSv2 evaluation complete\")\n",
        "\n",
        "            # Step 4: Display results\n",
        "            print(\"\\n4️⃣ Displaying results...\")\n",
        "            self.display_results(prompt, image_url, aesthetic_score, hpscore)\n",
        "\n",
        "            # Compile results\n",
        "            result = {\n",
        "                \"prompt\": prompt,\n",
        "                \"image_url\": image_url,\n",
        "                \"aesthetic_score\": aesthetic_score,\n",
        "                \"hpscore\": hpscore,\n",
        "                \"timestamp\": metadata[\"timestamp\"],\n",
        "                \"generation_time\": metadata[\"generation_time\"],\n",
        "                \"metadata\": metadata\n",
        "            }\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in generation: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def display_results(self, prompt: str, image_url: str, aesthetic_score: float, hpscore: float):\n",
        "        \"\"\"Display the image, prompt, and aesthetic score.\"\"\"\n",
        "        # Display prompt\n",
        "        display(HTML(f\"<h3>📝 Prompt: {prompt}</h3>\"))\n",
        "\n",
        "        # Display image\n",
        "        display(HTML(f'<img src=\"{image_url}\" style=\"max-width: 512px; max-height: 512px; border: 2px solid #ddd; border-radius: 8px;\"/>'))\n",
        "\n",
        "        # Display aesthetic score\n",
        "        display(HTML(f\"<h3>🎨 Aesthetic Score: {aesthetic_score:.2f}</h3>\"))\n",
        "\n",
        "        # Display HPSv2 score\n",
        "        display(HTML(f\"<h3>🎨 HPSv2 Score: {hpscore:.2f}</h3>\"))\n",
        "\n",
        "\n",
        "        print(f\"\\n📊 RESULTS SUMMARY:\")\n",
        "        print(f\"   Prompt: {prompt}\")\n",
        "        print(f\"   Aesthetic Score: {aesthetic_score:.2f}\")\n",
        "        print(f\"   HPSv2 Score: {hpscore:.2f}\")\n",
        "        print(f\"   Image URL: {image_url}\")\n",
        "\n",
        "print(\"✅ ImageGenerator class defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3a8f9fb9b5194380989fc53b58d0b8b7",
            "8fb79c8e00804766a4955b5a6f6d86ab",
            "b9af0aab20a1491e9a57baac09e6d4bc",
            "094f6ecc00b947568035865ce76cf0fa",
            "69413f8eb240463ca56716ea6f1383fc",
            "1780d986615549c78b8f040d26e1480e",
            "6851481180084746b19c5386c9b1bc7b",
            "152cabcfbaac44989ed852a04ed352eb",
            "d1ca5662678c4d6f87be2f45544fd563",
            "5c7d4174775c41b1acaaf0bf72cf2958",
            "4f50068a74c446d98429d329715f391f"
          ]
        },
        "id": "MjK2MsIT49u6",
        "outputId": "d9e7250f-aac7-459e-e594-e9a781246f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading aesthetic evaluation model...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a8f9fb9b5194380989fc53b58d0b8b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Aesthetic model loaded successfully!\n",
            "\n",
            "🎯 Generating image for prompt: 'a 5090 nvidia gpu. A product-centered illustration highlighting design functionality and aesthetic appeal showcasing an item or commercial product through detailed artistic visualization, rendered in the style of clay stop-motion animation, smooth gradient seamless color transitions blending, insert shot detailed close-up specific object element within scene, eye level frontal view'\n",
            "============================================================\n",
            "\n",
            "1️⃣ Generating image with FAL AI Imagen4...\n",
            "✅ Image generated in 9.31s\n",
            "\n",
            "2️⃣ Downloading image for evaluation...\n",
            "✅ Image downloaded successfully\n",
            "\n",
            "3️⃣ Calculating aesthetic score...\n",
            "✅ Aesthetic evaluation complete\n",
            "\n",
            "3️⃣ Calculating HPSv2 score...\n",
            "✅ HPSv2 evaluation complete\n",
            "\n",
            "4️⃣ Displaying results...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/hpsv2/img_score.py:107: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h3>📝 Prompt: a 5090 nvidia gpu. A product-centered illustration highlighting design functionality and aesthetic appeal showcasing an item or commercial product through detailed artistic visualization, rendered in the style of clay stop-motion animation, smooth gradient seamless color transitions blending, insert shot detailed close-up specific object element within scene, eye level frontal view</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<img src=\"https://v3.fal.media/files/zebra/cD-xZPCbL3KaQGOHVc4zR_output.png\" style=\"max-width: 512px; max-height: 512px; border: 2px solid #ddd; border-radius: 8px;\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>🎨 Aesthetic Score: 4.50</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>🎨 HPSv2 Score: 0.20</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<p>🔗 <a href='https://v3.fal.media/files/zebra/cD-xZPCbL3KaQGOHVc4zR_output.png' target='_blank'>View Full Image</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📊 RESULTS SUMMARY:\n",
            "   Prompt: a 5090 nvidia gpu. A product-centered illustration highlighting design functionality and aesthetic appeal showcasing an item or commercial product through detailed artistic visualization, rendered in the style of clay stop-motion animation, smooth gradient seamless color transitions blending, insert shot detailed close-up specific object element within scene, eye level frontal view\n",
            "   Aesthetic Score: 4.50\n",
            "   HPSv2 Score: 0.20\n",
            "   Image URL: https://v3.fal.media/files/zebra/cD-xZPCbL3KaQGOHVc4zR_output.png\n"
          ]
        }
      ],
      "source": [
        "example = 'a 5090 nvidia gpu. A product-centered illustration highlighting design functionality and aesthetic appeal showcasing an item or commercial product through detailed artistic visualization, rendered in the style of clay stop-motion animation, smooth gradient seamless color transitions blending, insert shot detailed close-up specific object element within scene, eye level frontal view'\n",
        "generator = ImageGenerator()\n",
        "result = generator.generate_and_evaluate(example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwTf3EWMMcF4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "omybrand",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "094f6ecc00b947568035865ce76cf0fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c7d4174775c41b1acaaf0bf72cf2958",
            "placeholder": "​",
            "style": "IPY_MODEL_4f50068a74c446d98429d329715f391f",
            "value": " 1/1 [00:00&lt;00:00, 124.60it/s]"
          }
        },
        "152cabcfbaac44989ed852a04ed352eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1780d986615549c78b8f040d26e1480e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a8f9fb9b5194380989fc53b58d0b8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fb79c8e00804766a4955b5a6f6d86ab",
              "IPY_MODEL_b9af0aab20a1491e9a57baac09e6d4bc",
              "IPY_MODEL_094f6ecc00b947568035865ce76cf0fa"
            ],
            "layout": "IPY_MODEL_69413f8eb240463ca56716ea6f1383fc"
          }
        },
        "4f50068a74c446d98429d329715f391f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c7d4174775c41b1acaaf0bf72cf2958": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6851481180084746b19c5386c9b1bc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69413f8eb240463ca56716ea6f1383fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb79c8e00804766a4955b5a6f6d86ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1780d986615549c78b8f040d26e1480e",
            "placeholder": "​",
            "style": "IPY_MODEL_6851481180084746b19c5386c9b1bc7b",
            "value": "Fetching 1 files: 100%"
          }
        },
        "b9af0aab20a1491e9a57baac09e6d4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_152cabcfbaac44989ed852a04ed352eb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1ca5662678c4d6f87be2f45544fd563",
            "value": 1
          }
        },
        "d1ca5662678c4d6f87be2f45544fd563": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
